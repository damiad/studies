{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/andrzejmizera/Multispectral-Edge-Filtered-Conditional-GAN/blob/main/cloudremoval_MEcGAN.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark:** If you find this case study code too complicated to start with, you may want to first have a look at this tutorial https://www.tensorflow.org/tutorials/generative/dcgan, which demonstrates how to generate images of handwritten digits using a Deep Convolutional Generative Adversarial Network (DCGAN)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LI-qwTv4oS9J"
   },
   "source": [
    "# Download Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f3s8jK58-Etx"
   },
   "source": [
    "The dataset can be downloaded with this link:\n",
    "\n",
    "https://drive.google.com/file/d/1sqII7SSnbpfGRGYx4r4w170-eelnPAve/view?usp=sharing\n",
    "\n",
    "Please upload it to your Google drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "# Set path to the dataset.zip file placed on your Google drive. \n",
    "zf = zipfile.ZipFile('dataset.zip')\n",
    "zf.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U6C1pe5m-Ety"
   },
   "source": [
    "# Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D4mr7BDr-Etz",
    "outputId": "66e5a1e3-49f0-4c0e-93d0-63516a059d0d"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "    raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))\n",
    "import numpy as np\n",
    "import cv2\n",
    "import progressbar\n",
    "import datetime\n",
    "import os\n",
    "import time\n",
    "import matplotlib\n",
    "\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Y64QUTo-Et2"
   },
   "source": [
    "# Prepare Data Piplines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eBxCBClu-Et3",
    "outputId": "e44e73dd-5598-48c5-d141-3c4dbf3c5402"
   },
   "outputs": [],
   "source": [
    "dir_rgb = 'dataset/RGB'\n",
    "dir_nir = 'dataset/NIR'\n",
    "dir_clouds = 'dataset/clouds'\n",
    "\n",
    "rgb_images = sorted(os.listdir(dir_rgb))\n",
    "rgb_images.remove('.DS_Store')\n",
    "cloud_images = sorted(os.listdir(dir_clouds))\n",
    "cloud_images.remove('.DS_Store')\n",
    "nir_images = sorted(os.listdir(dir_nir))\n",
    "nir_images.remove('.DS_Store')\n",
    "\n",
    "num_images = 528\n",
    "train_num_images = 428\n",
    "\n",
    "nir_cloud_intensity = 0.99\n",
    "\n",
    "print('Prepare Training Dataset')\n",
    "train_dataset_target_cloudfree_rgb = []\n",
    "train_dataset_clouded_rgb = []\n",
    "train_dataset_clouded_nir = []\n",
    "pbar = progressbar.ProgressBar()\n",
    "for i in pbar(range(train_num_images)):\n",
    "    target_cloudfree_rgb = plt.imread(os.path.join(dir_rgb, rgb_images[i])).astype(np.float32)\n",
    "    target_cloudfree_rgb = cv2.normalize(target_cloudfree_rgb, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "\n",
    "    cloud = plt.imread(os.path.join(dir_clouds, cloud_images[i])).astype(np.float32)\n",
    "    cloud = 255 * cloud\n",
    "    cloud[:, :, 3] = np.clip(cloud[:, :, 3] + 75.0, 0, 255.0)\n",
    "    alpha = cloud[:, :, 3] / 255.0\n",
    "    alpha = np.broadcast_to(alpha[:, :, None], alpha.shape + (3,))\n",
    "\n",
    "    # Merge RGB image with the selected cloud image.\n",
    "    clouded_rgb = (1. - alpha) * target_cloudfree_rgb + alpha * np.ones([256, 256, 3])\n",
    "    target_cloudfree_rgb = 2 * target_cloudfree_rgb - 1\n",
    "    clouded_rgb = 2 * clouded_rgb - 1\n",
    "\n",
    "    # Merge NIR image with the selected cloud image.    \n",
    "    nir = plt.imread(os.path.join(dir_nir, nir_images[i])).astype(np.float32)\n",
    "    nir = cv2.normalize(nir, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "    nir_cloud = cloud[:, :, 3] / 255\n",
    "    clouded_nir = (1. - nir_cloud_intensity * nir_cloud) * nir + nir_cloud_intensity * nir_cloud * np.ones([256, 256])\n",
    "    clouded_nir = 2 * clouded_nir - 1\n",
    "\n",
    "    train_dataset_target_cloudfree_rgb.append(target_cloudfree_rgb.astype(np.float32))\n",
    "    train_dataset_clouded_rgb.append(clouded_rgb.astype(np.float32))\n",
    "    train_dataset_clouded_nir.append(clouded_nir.astype(np.float32))\n",
    "\n",
    "train_dataset_target_cloudfree_rgb = tf.data.Dataset.from_tensor_slices(train_dataset_target_cloudfree_rgb)\n",
    "train_dataset_clouded_rgb = tf.data.Dataset.from_tensor_slices(train_dataset_clouded_rgb)\n",
    "train_dataset_clouded_nir = tf.data.Dataset.from_tensor_slices(train_dataset_clouded_nir)\n",
    "train_dataset = tf.data.Dataset.zip((train_dataset_clouded_rgb, train_dataset_target_cloudfree_rgb, train_dataset_clouded_nir))\n",
    "\n",
    "print('Prepare Test Dataset')\n",
    "test_dataset_target_cloudfree_rgb = []\n",
    "test_dataset_clouded_rgb = []\n",
    "test_dataset_clouded_nir = []\n",
    "pbar = progressbar.ProgressBar()\n",
    "for i in pbar(range(train_num_images, num_images)):\n",
    "    target_cloudfree_rgb = plt.imread(os.path.join(dir_rgb, rgb_images[i])).astype(np.float32)\n",
    "    target_cloudfree_rgb = cv2.normalize(target_cloudfree_rgb, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "\n",
    "    cloud = plt.imread(os.path.join(dir_clouds, cloud_images[i])).astype(np.float32)\n",
    "    cloud = 255 * cloud\n",
    "    cloud[:, :, 3] = np.clip(cloud[:, :, 3] + 75.0, 0, 255.0)\n",
    "    alpha = cloud[:, :, 3] / 255.0\n",
    "    alpha = np.broadcast_to(alpha[:, :, None], alpha.shape + (3,))\n",
    "\n",
    "    # Merge RGB image with the selected cloud image.\n",
    "    clouded_rgb = (1. - alpha) * target_cloudfree_rgb + alpha * np.ones([256, 256, 3])\n",
    "    target_cloudfree_rgb = 2 * target_cloudfree_rgb - 1\n",
    "    clouded_rgb = 2 * clouded_rgb - 1\n",
    "\n",
    "    # Merge NIR image with the selected cloud image.\n",
    "    nir = plt.imread(os.path.join(dir_nir, nir_images[i])).astype(np.float32)\n",
    "    nir = cv2.normalize(nir, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "    nir_cloud = cloud[:, :, 3] / 255\n",
    "    clouded_nir = (1. - nir_cloud_intensity * nir_cloud) * nir + nir_cloud_intensity * nir_cloud * np.ones([256, 256])\n",
    "    clouded_nir = 2 * clouded_nir - 1\n",
    "\n",
    "    test_dataset_target_cloudfree_rgb.append(target_cloudfree_rgb.astype(np.float32))\n",
    "    test_dataset_clouded_rgb.append(clouded_rgb.astype(np.float32))\n",
    "    test_dataset_clouded_nir.append(clouded_nir.astype(np.float32))\n",
    "\n",
    "test_dataset_target_cloudfree_rgb = tf.data.Dataset.from_tensor_slices(test_dataset_target_cloudfree_rgb)\n",
    "test_dataset_clouded_rgb = tf.data.Dataset.from_tensor_slices(test_dataset_clouded_rgb)\n",
    "test_dataset_clouded_nir = tf.data.Dataset.from_tensor_slices(test_dataset_clouded_nir)\n",
    "test_dataset = tf.data.Dataset.zip((test_dataset_clouded_rgb, test_dataset_target_cloudfree_rgb, test_dataset_clouded_nir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fzmzXl3Z-Et5"
   },
   "source": [
    "# GAN Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TwggaCmT-Et5"
   },
   "source": [
    "## Single Decoder and Encoder Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FcJj9Gxg-Et6"
   },
   "outputs": [],
   "source": [
    "# Single decoder layer \n",
    "def downsample(filters, size, apply_batchnorm=True):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(\n",
    "        tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n",
    "                               kernel_initializer=initializer, use_bias=False))\n",
    "    if apply_batchnorm:\n",
    "        result.add(tf.keras.layers.BatchNormalization())\n",
    "        result.add(tf.keras.layers.LeakyReLU())\n",
    "    return result\n",
    "\n",
    "# Single encoder layer\n",
    "def upsample(filters, size, apply_dropout=False):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\n",
    "                                               padding='same',\n",
    "                                               kernel_initializer=initializer,\n",
    "                                               use_bias=False))\n",
    "    result.add(tf.keras.layers.BatchNormalization())\n",
    "    if apply_dropout:\n",
    "        result.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "    result.add(tf.keras.layers.ReLU())\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s5FYID2G-Et7"
   },
   "source": [
    "## Generator Architecture and Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3D2ku-IR-Et8"
   },
   "outputs": [],
   "source": [
    "OUTPUT_CHANNELS = 3\n",
    "def Generator():\n",
    "    clouded_rgb = tf.keras.layers.Input(shape=[256, 256, 3], name='clouded_rgb')\n",
    "    clouded_nir = tf.keras.layers.Input(shape=[256, 256, 1], name='clouded_nir')\n",
    "    down_stack = [\n",
    "        downsample(64, 4, apply_batchnorm=False),\n",
    "        downsample(128, 4),\n",
    "        downsample(256, 4),\n",
    "        downsample(512, 4),\n",
    "        downsample(512, 4),\n",
    "        downsample(512, 4),\n",
    "        downsample(512, 4),\n",
    "        downsample(512, 4),\n",
    "    ]\n",
    "    up_stack = [\n",
    "        upsample(512, 4, apply_dropout=True),\n",
    "        upsample(512, 4, apply_dropout=True),\n",
    "        upsample(512, 4, apply_dropout=True),\n",
    "        upsample(512, 4),\n",
    "        upsample(256, 4),\n",
    "        upsample(128, 4),\n",
    "        upsample(64, 4),\n",
    "    ]\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    last = tf.keras.layers.Conv2DTranspose(OUTPUT_CHANNELS, 4,\n",
    "                                           strides=2,\n",
    "                                           padding='same',\n",
    "                                           kernel_initializer=initializer,\n",
    "                                           activation='tanh')  # (bs, 256, 256, 3)\n",
    "    x = tf.keras.layers.concatenate([clouded_rgb, clouded_nir])\n",
    "    # Downsampling through the model\n",
    "    skips = []\n",
    "    for down in down_stack:\n",
    "        x = down(x)\n",
    "        skips.append(x)\n",
    "    skips = reversed(skips[:-1])\n",
    "    # Upsampling and establishing the skip connections\n",
    "    for up, skip in zip(up_stack, skips):\n",
    "        x = up(x)\n",
    "        x = tf.keras.layers.Concatenate()([x, skip])\n",
    "    x = last(x)\n",
    "    return tf.keras.Model(inputs=[clouded_rgb, clouded_nir], outputs=x)\n",
    "\n",
    "LAMBDA = 1\n",
    "\n",
    "loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "\n",
    "def generator_loss(disc_generated_output, generated_cloudfree_rgb, target_cloudfree_rgb):\n",
    "    gan_loss = loss_object(tf.ones_like(disc_generated_output), disc_generated_output)\n",
    "    # mean absolute error\n",
    "    l1_loss = tf.reduce_mean(tf.abs(target_cloudfree_rgb - generated_cloudfree_rgb))\n",
    "    total_gen_loss = gan_loss + LAMBDA * l1_loss\n",
    "    return total_gen_loss, gan_loss, l1_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XPIB4Jq_-Et-"
   },
   "source": [
    "## Discriminator Architecture and Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GT0jrb8t-Et-"
   },
   "outputs": [],
   "source": [
    "def Discriminator():\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    # edge_clouded_nir = tf.keras.layers.Input(shape=[256, 256, 1], name='edge_clouded_nir')\n",
    "    cloud_free_rgb = tf.keras.layers.Input(shape=[256, 256, 3], name='cloud_free_rgb')\n",
    "    edge_cloud_free_rgb = tf.keras.layers.Input(shape=[256, 256, 1], name='edge_cloud_free_rgb')\n",
    "    # gray_edge_clouded_rgb = tf.keras.layers.Input(shape=[256, 256, 1], name='gray_edge_clouded_rgb')\n",
    "    x = tf.keras.layers.concatenate([cloud_free_rgb, edge_cloud_free_rgb])\n",
    "    down1 = downsample(64, 3, False)(x)\n",
    "    down2 = downsample(128, 3)(down1)\n",
    "    down3 = downsample(128, 3)(down2)\n",
    "    down4 = downsample(256, 3)(down3)\n",
    "    down5 = downsample(256, 3)(down4)\n",
    "    down6 = downsample(512, 3)(down5)\n",
    "    down7 = downsample(512, 3)(down6)\n",
    "    zero_pad1 = tf.keras.layers.ZeroPadding2D()(down7)\n",
    "    conv = tf.keras.layers.Conv2D(512, 3, strides=1,\n",
    "                                  kernel_initializer=initializer,\n",
    "                                  use_bias=False)(zero_pad1)\n",
    "    batchnorm1 = tf.keras.layers.BatchNormalization()(conv)\n",
    "    leaky_relu = tf.keras.layers.LeakyReLU()(batchnorm1)\n",
    "    zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu)\n",
    "    layer10 = tf.keras.layers.Conv2D(1, 3, strides=1,\n",
    "                                     kernel_initializer=initializer)(zero_pad2)\n",
    "    flatten_layer = tf.keras.layers.Flatten()(layer10)\n",
    "    dense = tf.keras.layers.Dense(1)(flatten_layer)\n",
    "    return tf.keras.Model(inputs=[cloud_free_rgb, edge_cloud_free_rgb], outputs=tf.keras.activations.sigmoid(dense))\n",
    "\n",
    "#loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def discriminator_loss(disc_real_output, disc_generated_output):\n",
    "    real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)\n",
    "    generated_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output)\n",
    "    total_disc_loss = real_loss + generated_loss\n",
    "    return total_disc_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JFFqswuM-EuA"
   },
   "source": [
    "# Visualize Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jRcKaWOC-EuA"
   },
   "outputs": [],
   "source": [
    "def display_images(generated_cloudfree_rgb, test_input, target_cloudfree_rgb):\n",
    "    plt.figure(figsize=(15,15))\n",
    "    display_list = [test_input[0][0], test_input[1][0,:,:,0], target_cloudfree_rgb[0], generated_cloudfree_rgb[0]]\n",
    "    title = ['Clouded RGB', 'Clouded NIR', 'Target Cloud-free RGB', 'Generated Cloud-free RGB']\n",
    "    for i in range(4):\n",
    "        plt.subplot(1, 4, i+1)\n",
    "        plt.title(title[i])\n",
    "        # getting the pixel values between [0, 1] to plot it.\n",
    "        if i==1:\n",
    "            plt.imshow((display_list[i].numpy() + 1)/2.0, cmap='gray')\n",
    "        else:\n",
    "            plt.imshow((display_list[i].numpy() + 1)/2.0)\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lTXSZpch-EuC"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TzkS8BSI-EuC",
    "outputId": "00733511-c182-49dd-c213-b62c6a73feeb"
   },
   "outputs": [],
   "source": [
    "# Notice the use of `tf.function`\n",
    "# This annotation causes the function to be \"compiled\".\n",
    "@tf.function\n",
    "def train_step(clouded_rgb, target_cloudfree_rgb, clouded_nir, epoch):\n",
    "    \n",
    "    # To better understand gradient tapes, please look at\n",
    "    #   https://www.tensorflow.org/guide/autodiff\n",
    "    # and \n",
    "    #   https://www.tensorflow.org/api_docs/python/tf/GradientTape.\n",
    "    # We use two independent gradient tapes, since calling the gradient() method destroys the tape.\n",
    "    # We need to call the method first to differentiate the losses with respect to the generator parameters\n",
    "    # and the discriminator parameters.\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        \n",
    "        # Generate cloud-free RGB image from clouded RGB image and its corresponding NIR image\n",
    "        # (notice that batch dimension is added to the images, and the colour dimension to the NIR image)\n",
    "        # training parameter: Boolean or boolean scalar tensor, indicating whether to run the Network in\n",
    "        #                     training mode or inference mode. \n",
    "        generated_cloudfree_rgb = generator([clouded_rgb[None, :, :, :], clouded_nir[None, :, :, None]], training=True)\n",
    "\n",
    "        # Grayscaling the generated cloud-free RGB image\n",
    "        gray_generated_cloudfree_rgb = tf.image.rgb_to_grayscale(generated_cloudfree_rgb)\n",
    "        # Applying edge detection on the grayscaled generated cloud-free RGB image (Sobel method)\n",
    "        sobel = tf.image.sobel_edges(gray_generated_cloudfree_rgb)\n",
    "        gray_edge_generated_cloudfree_rgb = sobel[:, :, :, :, 0] # sobel in y-direction\n",
    "\n",
    "        # Grayscaling the taget cloud-free RGB image (batch dimension needs to be added to apply\n",
    "        # the tf.image.rgb_to_grayscale function)\n",
    "        gray_target_cloudfree_rgb = tf.image.rgb_to_grayscale(target_cloudfree_rgb[None, :, :, :])\n",
    "        # Applying edge detection on the grayscaled generated cloud-free RGB image (Sobel method)\n",
    "        gray_edge_target_cloudfree_rgb = tf.image.sobel_edges(gray_target_cloudfree_rgb)\n",
    "        gray_edge_target_cloudfree_rgb = gray_edge_target_cloudfree_rgb[:, :, :, :, 0] # sobel in y-direction\n",
    "\n",
    "        # Apply the discriminator on the target cloud-free RGB images and their edges\n",
    "        # (notice that batch dimension is added to the target cloud-free RGB images)\n",
    "        disc_real_output = discriminator([target_cloudfree_rgb[None, :, :, :], gray_edge_target_cloudfree_rgb], training=True)\n",
    "        # Apply the discriminator on the generated cloud-free RGB iamges and their edges\n",
    "        disc_generated_output = discriminator([generated_cloudfree_rgb, gray_edge_generated_cloudfree_rgb], training=True)\n",
    "\n",
    "        # Compute the generator loss \n",
    "        gen_total_loss, gen_gan_loss, gen_l1_loss = generator_loss(disc_generated_output, generated_cloudfree_rgb,\n",
    "                                                                   target_cloudfree_rgb)\n",
    "        # Compute the generator loss for the discriminator output for the real images and generated images\n",
    "        disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
    "\n",
    "    # Compute the gradients for the generator\n",
    "    generator_gradients = gen_tape.gradient(gen_total_loss, generator.trainable_variables)\n",
    "    # Compute the gradients for the discriminator\n",
    "    discriminator_gradients = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "    \n",
    "    # Update the parameters of the generator\n",
    "    generator_optimizer.apply_gradients(zip(generator_gradients, generator.trainable_variables))\n",
    "    # Update the parameters of the discriminator\n",
    "    discriminator_optimizer.apply_gradients(zip(discriminator_gradients, discriminator.trainable_variables))\n",
    "\n",
    "    # Logging loss values\n",
    "    with summary_writer.as_default():\n",
    "        tf.summary.scalar('gen_total_loss', gen_total_loss, step=epoch)\n",
    "        tf.summary.scalar('gen_gan_loss', gen_gan_loss, step=epoch)\n",
    "        tf.summary.scalar('gen_l1_loss', gen_l1_loss, step=epoch)\n",
    "        tf.summary.scalar('disc_loss', disc_loss, step=epoch)\n",
    "\n",
    "dir_generated_cloud_free_images = 'results/' + 'generated_cloud_free_images_' + str(nir_cloud_intensity * 100) + 'eta_NIR'\n",
    "try:\n",
    "    os.makedirs(dir_generated_cloud_free_images)\n",
    "except OSError:\n",
    "    print(\"Directory %s already exists\" % dir_generated_cloud_free_images)\n",
    "\n",
    "def fit(train_ds, test_ds, start_from_epoch):\n",
    "    len_epochs = 10 ** (len(str(EPOCHS)))\n",
    "    for epoch in range(start_from_epoch - 1, EPOCHS):\n",
    "        print(\"Epoch: \", epoch + 1)\n",
    "        pbar = progressbar.ProgressBar(maxval=train_num_images)\n",
    "        pbar.start()\n",
    "        idx = 1\n",
    "        for _, all_images_in_batch in train_ds.enumerate():\n",
    "            train_step(all_images_in_batch[0], all_images_in_batch[1], all_images_in_batch[2], epoch)\n",
    "            pbar.update(idx)\n",
    "            idx = idx + 1\n",
    "        pbar.finish()\n",
    "\n",
    "        # saving generated cloud-free rgb images in every 10 epochs\n",
    "        if (epoch + 1) % 100 == 0:\n",
    "            id_im = 1\n",
    "            for example_clouded_rgb_image, example_target_cloudfree_rgb_image, example_clouded_nir in test_ds.take(num_images - train_num_images):\n",
    "                generated_cloud_free_image = generator([example_clouded_rgb_image[None, :, :, :], example_clouded_nir[None, :, :, None]], training=True)                \n",
    "                matplotlib.image.imsave(dir_generated_cloud_free_images + '/' + 'generated_cloud_free_rgb' + str(len_epochs + epoch + 1)[1:] + '_' + str(10 * (num_images - train_num_images) + id_im)[1:] + '.png', (1 + generated_cloud_free_image[0].numpy()) / 2)\n",
    "                # visualize generated cloud-free rgb images\n",
    "                display_images(generated_cloud_free_image, [example_clouded_rgb_image[None,:,:,:], example_clouded_nir[None,:,:,None]], example_target_cloudfree_rgb_image[None,:,:,:])\n",
    "                id_im = id_im + 1        \n",
    "        \n",
    "        # saving (checkpoint) the model in every 20 epochs\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "\n",
    "    checkpoint.save(file_prefix=checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pKfShukn-EuE"
   },
   "source": [
    "# Fit Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EHTwLnQwVy4l"
   },
   "outputs": [],
   "source": [
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ssOSAInZ-EuE"
   },
   "outputs": [],
   "source": [
    "log_dir = 'logs/'\n",
    "summary_writer = tf.summary.create_file_writer(log_dir + 'fit/' + datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "try:\n",
    "    os.mkdir(checkpoint_dir)\n",
    "except OSError:\n",
    "    print(\"Directory %s already exists\" % checkpoint_dir)\n",
    "\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
    "\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                              discriminator_optimizer=discriminator_optimizer,\n",
    "                              generator=generator,\n",
    "                              discriminator=discriminator)\n",
    "\n",
    "restore_checkpoint = False # To restore last checkpoint, set this to True \n",
    "if restore_checkpoint is False:\n",
    "    checkpoint_path = checkpoint_dir + '/training/cp-{epoch:04d}.ckpt'\n",
    "else:\n",
    "    checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "    \n",
    "EPOCHS = 500\n",
    "start_from_epoch = 1\n",
    "fit(train_dataset, test_dataset, start_from_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9895oEfjsZVj"
   },
   "source": [
    "# Use Saved Checkpoint to Generate Cloud-free RGB Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BpwZU_3eq2uK"
   },
   "outputs": [],
   "source": [
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "try:\n",
    "    os.mkdir(checkpoint_dir)\n",
    "except OSError:\n",
    "    print(\"Directory %s already exists\" % checkpoint_dir)\n",
    "\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
    "\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                              discriminator_optimizer=discriminator_optimizer,\n",
    "                              generator=generator,\n",
    "                              discriminator=discriminator)\n",
    "\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "\n",
    "for example_clouded_rgb_image, example_target_cloudfree_rgb_image, example_clouded_nir in test_dataset.take(num_images - train_num_images):\n",
    "  generated_cloud_free_image = generator([example_clouded_rgb_image[None, :, :, :], example_clouded_nir[None, :, :, None]], training=True)                    \n",
    "  # visualize generated cloud-free rgb images\n",
    "  display_images(generated_cloud_free_image, [example_clouded_rgb_image[None,:,:,:], example_clouded_nir[None,:,:,None]], example_target_cloudfree_rgb_image[None,:,:,:])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(generated_images, save_dir):\n",
    "    try:\n",
    "        os.mkdir(save_dir)\n",
    "    except OSError:\n",
    "        print(\"Directory %s already exists\" % save_dir)\n",
    "\n",
    "    for i, generated_image in enumerate(generated_images):\n",
    "        save_path = os.path.join(save_dir, f'image_{i}.png')\n",
    "        plt.imsave(save_path, (generated_image.numpy() + 1) / 2.0)\n",
    "        \n",
    "save_dir = './generated_images'\n",
    "save_images(generated_cloud_free_image, save_dir)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cloudremoval_MEcGAN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
